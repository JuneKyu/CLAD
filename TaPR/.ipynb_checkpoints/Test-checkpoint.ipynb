{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:16:00.285830Z",
     "start_time": "2019-09-04T08:16:00.282239Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, getopt\n",
    "import time, datetime\n",
    "from typing import Callable\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:19:00.925320Z",
     "start_time": "2019-09-04T08:19:00.917912Z"
    }
   },
   "outputs": [],
   "source": [
    "# To store a single anomaly\n",
    "class Term:\n",
    "    def __init__(self, first, last, name):\n",
    "        self._first_timestamp = first\n",
    "        self._last_timestamp = last\n",
    "        self._name = name\n",
    "\n",
    "    def set_time(self, first, last):\n",
    "        self._first_timestamp = first\n",
    "        self._last_timestamp = last\n",
    "\n",
    "    def get_time(self):\n",
    "        return self._first_timestamp, self._last_timestamp\n",
    "\n",
    "    def set_name(self, str):\n",
    "        self._name = str\n",
    "\n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self._first_timestamp == other.get_time()[0] and self._last_timestamp == other.get_time()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:49:47.561284Z",
     "start_time": "2019-09-04T08:49:47.518968Z"
    }
   },
   "outputs": [],
   "source": [
    "class TaPR:\n",
    "    def __init__(self, label, theta, delta):\n",
    "        self._predictions = []  # list of Terms\n",
    "        self._anomalies = []    # list of Terms\n",
    "        self._ambiguous_inst = [] # list of Terms\n",
    "\n",
    "        self._set_predictions = False\n",
    "        self._set_anomalies = False\n",
    "\n",
    "        assert(len(label) == 2)\n",
    "        self._normal_lbl = label[0]\n",
    "        self._anomal_lbl = label[1]\n",
    "\n",
    "        self._theta = theta\n",
    "        self._delta = delta\n",
    "        pass\n",
    "\n",
    "    def load_predictions(self, filename):\n",
    "        ntoken = self._check_file_format(filename)\n",
    "\n",
    "        if ntoken == 1:\n",
    "            self._predictions = self._load_timeseries_file(filename)\n",
    "        else:\n",
    "            self._predictions = self._load_range_file(filename)\n",
    "        self._set_prediction = True\n",
    "\n",
    "\n",
    "    def load_anomalies(self, filename):\n",
    "        ntoken = self._check_file_format(filename)\n",
    "\n",
    "        if ntoken == 1:\n",
    "            self._anomalies = self._load_timeseries_file(filename)\n",
    "        else:\n",
    "            self._anomalies = self._load_range_file(filename)\n",
    "        self._set_anomalies = True\n",
    "\n",
    "        self._gen_ambiguous()\n",
    "\n",
    "\n",
    "    def _gen_ambiguous(self):\n",
    "        for i in range(len(self._anomalies)):\n",
    "            start_id = self._anomalies[i].get_time()[1] + 1\n",
    "            end_id = start_id + self._delta -1\n",
    "\n",
    "            #if the next anomaly occurs during the theta, update the end_id\n",
    "            if i+1 < len(self._anomalies) and end_id > self._anomalies[i+1].get_time()[0]:\n",
    "                end_id = self._anomalies[i+1].get_time()[0]\n",
    "\n",
    "            self._ambiguous_inst.append(Term(start_id, end_id, str(i)))\n",
    "\n",
    "\n",
    "    def _check_file_format(self, filename):\n",
    "        # check the file's format\n",
    "        f = open(filename, 'r', encoding='utf-8', newline='')\n",
    "        line = f.readline()\n",
    "        token = line.strip().split(',')\n",
    "        f.close()\n",
    "        return len(token)\n",
    "\n",
    "    def _load_range_file(self, filename):\n",
    "        temp_list = []\n",
    "        f = open(filename, 'r', encoding='utf-8', newline='')\n",
    "        for line in f.readlines():\n",
    "            items = line.strip().split(',')\n",
    "            if len(items) > 2:\n",
    "                temp_list.append(Term(int(items[0]), int(items[1]), str(items[2])))\n",
    "            else:\n",
    "                temp_list.append(Term(int(items[0]), int(items[1]), 'undefined'))\n",
    "        f.close()\n",
    "        return temp_list\n",
    "\n",
    "    def _load_timeseries_file(self, filename):\n",
    "        return_list = []\n",
    "        start_id = -1\n",
    "        id = 0\n",
    "        range_id = 1\n",
    "        #set prev_val as a value different to normal and anomalous labels\n",
    "        prev_val = self._anomal_lbl-1\n",
    "        if prev_val == self._normal_lbl:\n",
    "            prev_val -= 1\n",
    "\n",
    "        f = open(filename, 'r', encoding='utf-8', newline='')\n",
    "        for line in f.readlines():\n",
    "            val = int(line.strip().split()[0])\n",
    "\n",
    "            if val == self._anomal_lbl and prev_val == self._normal_lbl:\n",
    "                start_id = id\n",
    "            elif val == self._normal_lbl and prev_val == self._anomal_lbl:\n",
    "                return_list.append(Term(start_id, id - 1, str(range_id)))\n",
    "                range_id += 1\n",
    "                start_id = 0\n",
    "            elif start_id == -1 and val == self._anomal_lbl:\n",
    "                start_id = 0\n",
    "\n",
    "            id += 1\n",
    "            prev_val = val\n",
    "        f.close()\n",
    "        if start_id != 0:\n",
    "            return_list.append(Term(start_id, id-1, str(range_id)))\n",
    "\n",
    "        return return_list\n",
    "\n",
    "\n",
    "    def get_n_predictions(self):\n",
    "        return len(self._predictions)\n",
    "\n",
    "    def get_n_anomalies(self):\n",
    "        return len(self._anomalies)\n",
    "\n",
    "    # return a value with the detected anomaly list\n",
    "    def TaR_d(self) -> {float, list}:\n",
    "        total_score = 0.0\n",
    "        detected_anomalies = []\n",
    "        for anomaly_id in range(len(self._anomalies)):\n",
    "            anomaly = self._anomalies[anomaly_id]\n",
    "            ambiguous = self._ambiguous_inst[anomaly_id]\n",
    "\n",
    "            max_score = self._sum_of_func(anomaly.get_time()[0], anomaly.get_time()[1],\n",
    "                                          anomaly.get_time()[0], anomaly.get_time()[1], self._uniform_func)\n",
    "\n",
    "            score = 0.0\n",
    "            for prediction in self._predictions:\n",
    "                score += self._overlap_and_subsequent_score(anomaly, ambiguous, prediction)\n",
    "\n",
    "            if min(1.0, score / max_score) > self._theta:\n",
    "                total_score += 1.0\n",
    "                detected_anomalies.append(anomaly)\n",
    "\n",
    "        if len(self._anomalies) == 0:\n",
    "            return 0.0, []\n",
    "        else:\n",
    "            return total_score / len(self._anomalies), detected_anomalies\n",
    "\n",
    "    # return a value with the detected prediction lists\n",
    "    def TaP_d(self) -> {float, list}:\n",
    "        correct_predictions = []\n",
    "        total_score = 0.0\n",
    "        for prediction in self._predictions:\n",
    "            max_score = prediction.get_time()[1] - prediction.get_time()[0] + 1\n",
    "\n",
    "            score = 0.0\n",
    "            for anomaly_id in range(len(self._anomalies)):\n",
    "                anomaly = self._anomalies[anomaly_id]\n",
    "                ambiguous = self._ambiguous_inst[anomaly_id]\n",
    "\n",
    "                score += self._overlap_and_subsequent_score(anomaly, ambiguous, prediction)\n",
    "\n",
    "            if (score/max_score) > self._theta:\n",
    "                total_score += 1.0\n",
    "                correct_predictions.append(prediction)\n",
    "\n",
    "        if len(self._predictions) == 0:\n",
    "            return 0.0, []\n",
    "        else:\n",
    "            return total_score / len(self._predictions), correct_predictions\n",
    "\n",
    "\n",
    "    def _detect(self, src_range: Term, ranges: list, theta: int) -> bool:\n",
    "        rest_len = src_range.get_time()[1] - src_range.get_time()[0] + 1\n",
    "        for dst_range in ranges:\n",
    "            len = self._overlapped_len(src_range, dst_range)\n",
    "            if len != -1:\n",
    "                rest_len -= len\n",
    "        return (float)(rest_len) / (src_range.get_time()[1] - src_range.get_time()[0] + 1) <= (1.0 - theta)\n",
    "\n",
    "    def _overlapped_len(self, range1: Term, range2: Term) -> int:\n",
    "        detected_start = max(range1.get_time()[0], range2.get_time()[0])\n",
    "        detected_end = min(range1.get_time()[1], range2.get_time()[1])\n",
    "\n",
    "        if detected_end < detected_start:\n",
    "            return 0\n",
    "        else:\n",
    "            return detected_end - detected_start + 1\n",
    "\n",
    "    def _min_max_norm(self, value: int, org_min: int, org_max: int, new_min: int, new_max: int) -> float:\n",
    "        return (float)(new_min) + (float)(value - org_min) * (new_max - new_min) / (org_max - org_min)\n",
    "\n",
    "    def _decaying_func(self, val: float) -> float:\n",
    "        assert (-6 <= val <= 6)\n",
    "        return 1 / (1 + math.exp(val))\n",
    "\n",
    "    def _ascending_func(self, val: float) -> float:\n",
    "        assert (-6 <= val <= 6)\n",
    "        return 1 / (1 + math.exp(val * -1))\n",
    "\n",
    "    def _uniform_func(self, val: float) -> float:\n",
    "        return 1.0\n",
    "\n",
    "    def _sum_of_func(self, start_time: int, end_time: int, org_start: int, org_end: int,\n",
    "                     func: Callable[[float], float]) -> float:\n",
    "        val = 0.0\n",
    "        for timestamp in range(start_time, end_time + 1):\n",
    "            val += func(self._min_max_norm(timestamp, org_start, org_end, -6, 6))\n",
    "        return val\n",
    "\n",
    "    def _overlap_and_subsequent_score(self, anomaly: Term, ambiguous: Term, prediction: Term) -> float:\n",
    "        score = 0.0\n",
    "\n",
    "        detected_start = max(anomaly.get_time()[0], prediction.get_time()[0])\n",
    "        detected_end = min(anomaly.get_time()[1], prediction.get_time()[1])\n",
    "\n",
    "        score += self._sum_of_func(detected_start, detected_end,\n",
    "                                   anomaly.get_time()[0], anomaly.get_time()[1], self._uniform_func)\n",
    "\n",
    "        detected_start = max(ambiguous.get_time()[0], prediction.get_time()[0])\n",
    "        detected_end = min(ambiguous.get_time()[1], prediction.get_time()[1])\n",
    "\n",
    "        score += self._sum_of_func(detected_start, detected_end,\n",
    "                                   ambiguous.get_time()[0], ambiguous.get_time()[1], self._decaying_func)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def TaR_p(self) -> float:\n",
    "        total_score = 0.0\n",
    "        for anomaly_id in range(len(self._anomalies)):\n",
    "            anomaly = self._anomalies[anomaly_id]\n",
    "            ambiguous = self._ambiguous_inst[anomaly_id]\n",
    "\n",
    "            max_score = self._sum_of_func(anomaly.get_time()[0], anomaly.get_time()[1],\n",
    "                                          anomaly.get_time()[0], anomaly.get_time()[1], self._uniform_func)\n",
    "\n",
    "            score = 0.0\n",
    "            for prediction in self._predictions:\n",
    "                score += self._overlap_and_subsequent_score(anomaly, ambiguous, prediction)\n",
    "\n",
    "            total_score += min(1.0, score/max_score)\n",
    "\n",
    "        if len(self._anomalies) == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return total_score / len(self._anomalies)\n",
    "\n",
    "    def TaP_p(self) -> float:\n",
    "        total_score = 0.0\n",
    "        for prediction in self._predictions:\n",
    "            max_score = prediction.get_time()[1] - prediction.get_time()[0] + 1\n",
    "\n",
    "            score = 0.0\n",
    "            for anomaly_id in range(len(self._anomalies)):\n",
    "                anomaly = self._anomalies[anomaly_id]\n",
    "                ambiguous = self._ambiguous_inst[anomaly_id]\n",
    "\n",
    "                score += self._overlap_and_subsequent_score(anomaly, ambiguous, prediction)\n",
    "\n",
    "            total_score += score/max_score\n",
    "\n",
    "        if len(self._predictions) == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return total_score / len(self._predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:49:20.486168Z",
     "start_time": "2019-09-04T08:49:20.483055Z"
    }
   },
   "outputs": [],
   "source": [
    "anomaly_file = './samples/swat.csv'\n",
    "predict_file = './samples/ocsvm.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:49:21.407854Z",
     "start_time": "2019-09-04T08:49:21.404444Z"
    }
   },
   "outputs": [],
   "source": [
    "delta = 180\n",
    "theta = 0.5\n",
    "alpha = 0.5\n",
    "label = [1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:49:22.530891Z",
     "start_time": "2019-09-04T08:49:22.018970Z"
    }
   },
   "outputs": [],
   "source": [
    "ev = TaPR(label, theta, delta)\n",
    "\n",
    "ev.load_anomalies(anomaly_file)\n",
    "ev.load_predictions(predict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T08:51:30.297754Z",
     "start_time": "2019-09-04T08:51:30.122892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5428571428571428 [<__main__.Term object at 0x7f170cc4b710>, <__main__.Term object at 0x7f170cc4b860>, <__main__.Term object at 0x7f170cc4bb70>, <__main__.Term object at 0x7f170cc4bc50>, <__main__.Term object at 0x7f170cc4be10>, <__main__.Term object at 0x7f170cc4be80>, <__main__.Term object at 0x7f170cc4bef0>, <__main__.Term object at 0x7f170cc4bf60>, <__main__.Term object at 0x7f170cc4bfd0>, <__main__.Term object at 0x7f170cc4c080>, <__main__.Term object at 0x7f170cc4c0f0>, <__main__.Term object at 0x7f170cc4c160>, <__main__.Term object at 0x7f170cc4c1d0>, <__main__.Term object at 0x7f170cc4c240>, <__main__.Term object at 0x7f170cc4c2b0>, <__main__.Term object at 0x7f170cc4c320>, <__main__.Term object at 0x7f170cc4c390>, <__main__.Term object at 0x7f170cc4c400>, <__main__.Term object at 0x7f170cc4c470>]\n",
      "0.5588583994509685\n",
      "\n",
      "[TaR]: 0.55086\n",
      "\t* Detection score: 0.54286\n"
     ]
    }
   ],
   "source": [
    "tard_value, detected_list = ev.TaR_d()\n",
    "tarp_value = ev.TaR_p()\n",
    "\n",
    "print('\\n[TaR]:',  \"%0.5f\"%(alpha*tard_value + (1-alpha)*tarp_value))\n",
    "print(\"\\t* Detection score:\", \"%0.5f\"%tard_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
